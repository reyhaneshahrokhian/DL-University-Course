{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "lduYbBQnuMHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_vlXTA-nq3w-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FhYqkwUDqer6"
      },
      "outputs": [],
      "source": [
        "class model:\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        self._initalize_parameters()\n",
        "        self._initalize_moms()\n",
        "        self._initalize_RMSs()\n",
        "\n",
        "    def _initalize_parameters(self):\n",
        "        self.weights_1 = self._random_tensor((x.shape[1],3))\n",
        "        self.bias_1 = self._random_tensor(1)\n",
        "        self.weights_2 = self._random_tensor((3,1))\n",
        "        self.bias_2 = self._random_tensor(1)\n",
        "\n",
        "    def _random_tensor(self, size): return (torch.randn(size)).requires_grad_()\n",
        "\n",
        "    def _initalize_moms(self):\n",
        "        self.moms_w1, self.moms_b1 = [0], [0]\n",
        "        self.moms_w2, self.moms_b2 = [0], [0]\n",
        "\n",
        "    def _initalize_RMSs(self):\n",
        "        self.RMSs_w1, self.RMSs_b1 = [0], [0]\n",
        "        self.RMSs_w2, self.RMSs_b2 = [0], [0]\n",
        "    def _nn(self, xb):\n",
        "        l1 = xb @ self.weights_1 + self.bias_1\n",
        "        l2 = l1.max(torch.tensor(0.0))\n",
        "        l3 = l2 @ self.weights_2 + self.bias_2\n",
        "        return l3\n",
        "\n",
        "    def _loss_func(self, preds, yb):\n",
        "        return ((preds-yb)**2).mean()\n",
        "\n",
        "    def train(self, optimizer):\n",
        "        # Multiple learning rates to see how optimizers work with them\n",
        "        lrs = [10E-4,10E-3,10E-2,10E-1]\n",
        "        ## for plotting ##\n",
        "        fig, axs = plt.subplots(2,2)\n",
        "        ## for plotting ##\n",
        "        all_losses = []\n",
        "        for i, lr in enumerate(lrs):\n",
        "            losses = []\n",
        "            while(len(losses) == 0 or losses[-1] > 0.1 and len(losses) < 1000):\n",
        "                preds = self._nn(self.x)\n",
        "                loss = self._loss_func(preds, self.y)\n",
        "                loss.backward()\n",
        "                optimizer(self.weights_1, lr, self.moms_w1, self.RMSs_w1)\n",
        "                optimizer(self.bias_1, lr, self.moms_b1, self.RMSs_b1)\n",
        "                optimizer(self.weights_2, lr, self.moms_w2, self.RMSs_w2)\n",
        "                optimizer(self.bias_2, lr, self.moms_b2, self.RMSs_b2)\n",
        "                losses.append(loss.item())\n",
        "            all_losses.append(losses)\n",
        "\n",
        "            ## for plotting ##\n",
        "            xi = i%2\n",
        "            yi = int(i/2)\n",
        "            axs[xi,yi].plot(list(range(len(losses))), losses)\n",
        "            axs[xi,yi].set_ylim(0, 30)\n",
        "            axs[xi,yi].set_title('Learing Rate: '+str(lr))\n",
        "            ## for plotting ##\n",
        "\n",
        "            # Setting seed makes sure the parameters are initalized the same way for better comparison\n",
        "            torch.manual_seed(42)\n",
        "            self._initalize_parameters()\n",
        "            self._initalize_moms()\n",
        "            self._initalize_RMSs()\n",
        "\n",
        "        ## for plotting ##\n",
        "        for ax in axs.flat:\n",
        "            ax.set(xlabel='steps', ylabel='loss (MSE)')\n",
        "        plt.tight_layout()\n",
        "        ## for plotting ##"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This simple function is implemented to generate y values from x values."
      ],
      "metadata": {
        "id": "5PVqUtpBuR4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_labels(x3, x2, x1):\n",
        "    return (x3**3 * 0.8) + (x2**2 * 0.1) + (x1 * 0.5) + 4."
      ],
      "metadata": {
        "id": "-JTgoyZcqnEk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[0.7,0.3,0.7],\n",
        "                  [0.4, 1., 0.4],\n",
        "                  [0.2, 1.1, 0.1],\n",
        "                  [0.4, 0.7, 0.2],\n",
        "                  [0.1, 0.5, 0.3]])\n",
        "y = torch.tensor([generate_fake_labels(i[0],i[1],i[2]) for i in x])\n",
        "print(x.shape, y.shape, y)"
      ],
      "metadata": {
        "id": "GsokscStqpqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([4.6334, 4.3512, 4.1774, 4.2002, 4.1758])"
      ],
      "metadata": {
        "id": "LKQj4Fu9qspy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = model(x, y)"
      ],
      "metadata": {
        "id": "btm-7Un9F3nx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are a few optimizer functions. Use them for the given model and Compare and report their results."
      ],
      "metadata": {
        "id": "5O6DinowuqNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SGD(a, lr, _, __):\n",
        "    a.data -= a.grad * lr\n",
        "    a.grad = None"
      ],
      "metadata": {
        "id": "JqcHBgsDqu0D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model with SGD\n",
        "my_model.train(SGD)"
      ],
      "metadata": {
        "id": "g0JUCjyfqw-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def momentum(a, _, moms, __):\n",
        "    previous_momentum = moms[-1]\n",
        "\n",
        "    mom = a.grad * 0.1 + previous_momentum * 0.9\n",
        "    moms.append(mom)\n",
        "    a.data -= mom\n",
        "    a.grad = None"
      ],
      "metadata": {
        "id": "-zPIClrmrQ_Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model with momentum\n",
        "my_model.train(momentum)"
      ],
      "metadata": {
        "id": "1wjfK3qLsNuX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}