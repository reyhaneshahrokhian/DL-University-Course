{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "je0pD2TSICi6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Download and load training data\n",
        "trainset = datasets.FashionMNIST('./data',download=True, train= True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 64, shuffle=True)\n",
        "\n",
        "# Download and load test data\n",
        "testset = datasets.FashionMNIST('./data',download=True, train= False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size= 64, shuffle=True)"
      ],
      "metadata": {
        "id": "fHXjbP9rIJv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = ('T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt','Sneaker', 'Bag', 'Ankle Boot')\n",
        "fig = plt.figure(figsize=(10,10));\n",
        "columns = 4;\n",
        "rows = 5;\n",
        "for i in range(1, 10):\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    fig.tight_layout()\n",
        "    plt.imshow(trainset.train_data[i].numpy(), cmap='gray')\n",
        "    plt.title('Training Label : %s' % labels_map[trainset.train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n1BN3BUwI6ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part a"
      ],
      "metadata": {
        "id": "aKJDyRWXJnfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "out_size = 10"
      ],
      "metadata": {
        "id": "LX02zMCeJCfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the model\n",
        "################ Your code ############\n",
        "model = nn.Sequential(\n",
        "\n",
        ")\n",
        "#######################################"
      ],
      "metadata": {
        "id": "7YlP2ve7KBTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ Your code ############\n",
        "criterion = ...\n",
        "optimizer = ...\n",
        "#######################################"
      ],
      "metadata": {
        "id": "yTu2Opx4LlkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "6Ht3JkkjKZ55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train your model\n",
        "epochs = 10\n",
        "\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "\n",
        "    images = images.view(images.shape[0],-1)\n",
        "\n",
        "    #reset the default gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    ################ Your code ############\n",
        "    output = ...\n",
        "    loss = ...\n",
        "    #######################################\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss = running_loss+loss.item()\n",
        "  else:\n",
        "    print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "metadata": {
        "id": "-G_9wk87KehM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test your model\n",
        "from d2l import torch as d2l\n",
        "d2l.predict_ch3(model,testloader,n = 10)"
      ],
      "metadata": {
        "id": "R1TD7mF_KkHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part b"
      ],
      "metadata": {
        "id": "BS1HDtG3OpYc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPfXRzZOLHgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part c"
      ],
      "metadata": {
        "id": "koz_Yd8jRFIe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrCKW9LNRGBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}